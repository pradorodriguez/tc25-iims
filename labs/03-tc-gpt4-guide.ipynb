{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract image content with Azure AI Chat-GPT4o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "* [Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-services/openai-service)\n",
    "  * GPT-4o\n",
    "* Python environment, version 3.10 or higher\n",
    "* Visual Studio Code\n",
    "  * Extensions: Python and Jupyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Utility Functions\n",
    "from utils import (\n",
    "    word_wrap,\n",
    "    local_image_to_data_url    \n",
    ")\n",
    "\n",
    "# OpenAI Python libraries\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load variables\n",
    "load_dotenv()\n",
    "\n",
    "# Variables - Azure Services\n",
    "AZURE_OPENAI_ACCOUNT=os.environ[\"AZURE_OPENAI_ACCOUNT\"]\n",
    "AZURE_OPENAI_KEY=os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "\n",
    "# Variables - Names\n",
    "azure_openai_gpt4o_name=\"gpt-4o\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI Call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureOpenAI call using a local image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI client object\n",
    "# Python AzureOpenAI Class: https://github.com/openai/openai-python?tab=readme-ov-file#microsoft-azure-openai\n",
    "openai_client=AzureOpenAI(\n",
    "     api_version=\"2024-06-01\",\n",
    "     azure_endpoint=AZURE_OPENAI_ACCOUNT,     \n",
    "     api_key=AZURE_OPENAI_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureOpenAI call using a a Local Image\n",
    "\n",
    "1. First convert the image file to base64 so it can be passed to the API\n",
    "1. Send the base64 file to Azure OpenAI API using the image_url field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add and test local image 1\n",
    "image_path='../images-lab-tests/seattle-pikeplace-1.jpg'\n",
    "data_url=local_image_to_data_url(image_path)\n",
    "#print(\"Data URL:\", data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI message content only:\n",
      "**Brief Description:**  \n",
      "The image showcases the iconic Pike Place Market in Seattle, Washington, a\n",
      "popular tourist destination known for its vibrant atmosphere, local produce, and unique shops. The\n",
      "scene features the famous \"Public Market Center\" neon sign with its clock, bustling market\n",
      "entrances, and wet brick-paved streets, indicating rainy weather typical of the\n",
      "region.\n",
      "\n",
      "**Entities:**  \n",
      "- Pike Place Market  \n",
      "- \"Public Market Center\" sign  \n",
      "- \"Meet the\n",
      "Producer\" sign  \n",
      "- \"Farmers Market\" entrance  \n",
      "- Seattle, Washington  \n",
      "- Clock on the \"Public\n",
      "Market Center\" sign  \n",
      "- Cars parked in front of the market  \n",
      "- Individuals walking near the market \n",
      "\n",
      "\n",
      "**Text in the Image:**  \n",
      "- \"PUBLIC MARKET CENTER\"  \n",
      "- \"FARMERS MARKET\"  \n",
      "- \"MEET THE PRODUCER\" \n",
      "\n",
      "- \"Seattle, Washington\"  \n",
      "\n",
      "**Compiled Paragraph:**  \n",
      "The image depicts Pike Place Market, a\n",
      "hallmark of Seattle, Washington, characterized by its vibrant surroundings and community-focused\n",
      "atmosphere. At the heart of the scene is the iconic \"Public Market Center\" neon sign with its red\n",
      "lettering and large clock. To the right of the market, the \"Meet the Producer\" banner can be seen\n",
      "atop the building, inviting patrons to engage with local vendors. The \"Farmers Market\" entrance is\n",
      "prominently displayed, leading into the bustling interior where visitors shop for local goods. The\n",
      "foreground features brick-paved streets glistening from the rain and cars parked in front of the\n",
      "market, while passersby navigate the lively marketplace, adding to the charm of this Pacific\n",
      "Northwest landmark.\n"
     ]
    }
   ],
   "source": [
    "response=openai_client.chat.completions.create(\n",
    "    model=azure_openai_gpt4o_name,\n",
    "    messages=[\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a Visual Cognitive system tasked with extracting text and information from images.\" \n",
    "        },\n",
    "        { \n",
    "            \"role\": \"user\", \n",
    "            \"content\": [  \n",
    "                { \n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": \"Extract all the following data in different sections from the provided \\\n",
    "                        image and compile it into a paragraph: Brief description, Entities, and Text in the image.\"\n",
    "                    \n",
    "                },\n",
    "                { \n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": data_url                        \n",
    "                    }\n",
    "                }\n",
    "            ] \n",
    "        } \n",
    "    ],\n",
    "    #  Set a \"max_tokens\" value, or the return output will be cut off\n",
    "    max_tokens=3000 \n",
    ")\n",
    "\n",
    "print(f\"Azure OpenAI message content only:\\n{word_wrap(response.choices[0].message.content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AzureOpenAI call using a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the image URL\n",
    "url = 'https://learn.microsoft.com/azure/ai-services/computer-vision/media/quickstarts/presentation.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI message content only:\n",
      "**Brief description:**  \n",
      "The image shows a modern office environment with a large interactive\n",
      "display screen. The screen depicts a scheduling or meeting interface, and a person in a yellow\n",
      "sweater uses touch gestures to interact with it. The background includes plants, office furniture,\n",
      "and a whiteboard.\n",
      "\n",
      "**Tags:**  \n",
      "Interactive display, office technology, touchscreen, meeting\n",
      "interface, scheduling, desk, modern workspace, plants, presentation.\n",
      "\n",
      "**Text in the image:**  \n",
      "-\n",
      "**9:35 AM**  \n",
      "  Conference room | 56498554  \n",
      "  555-123-4957  \n",
      "\n",
      "- **Town Hall**  \n",
      "  9:00 AM - 10:00\n",
      "AM  \n",
      "  Aaron Buxton  \n",
      "  *Join*  \n",
      "\n",
      "- **Daily SCRUM**  \n",
      "  10:00 AM - 11:00 AM  \n",
      "  Charlotte De Courn \n",
      "\n",
      "\n",
      "- **Quarterly All Hands**  \n",
      "  11:00 AM - 12:00 PM  \n",
      "  Sohail Sharma  \n",
      "\n",
      "- **Weekly Stand-up**  \n",
      " \n",
      "12:00 PM - 12:30 PM  \n",
      "  Danielle Manara  \n",
      "\n",
      "- **Product review**  \n"
     ]
    }
   ],
   "source": [
    "#query=\"Extract all the text from the provided image and compile it into a paragraph.\"\n",
    "\n",
    "response=openai_client.chat.completions.create(\n",
    "    model=azure_openai_gpt4o_name,\n",
    "    messages=[\n",
    "        { \n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You are a Visual Cognitive system tasked with extracting text and information from images.\" \n",
    "        },\n",
    "        { \n",
    "            \"role\": \"user\", \n",
    "            \"content\": [  \n",
    "                { \n",
    "                    \"type\": \"text\", \n",
    "                    \"text\": \"Using the image provided by image_url, get the following information: \\\n",
    "                        Brief description, Tags, and Text in the image.\"\n",
    "                    \n",
    "                },\n",
    "                { \n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": url                        \n",
    "                    }\n",
    "                }\n",
    "            ] \n",
    "        } \n",
    "    ],\n",
    "    #  Set a \"max_tokens\" value, or the return output will be cut off\n",
    "    max_tokens=3000 \n",
    ")\n",
    "\n",
    "print(f\"Azure OpenAI message content only:\\n{word_wrap(response.choices[0].message.content)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
